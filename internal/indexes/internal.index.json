[
  {
    "name": "architectural_mandates.md",
    "size_bytes": 908,
    "preview_lines": [
      "# Architectural Mandates",
      "",
      "This document serves as the single, unbreakable source of truth for foundational architectural decisions for the Agent Zero Vault project. The Sentinel Protocol is required to read and enforce these mandates before any implementation.",
      "",
      "---",
      "",
      "## 1. Runtime Data Validation Library",
      "",
      "- **Mandate:** The project will use **ArkType** for all runtime data validation.",
      "- **Rationale:** After a comparative analysis, ArkType was selected over Zod for its superior \"type-first\" architecture, which provides a true single source of truth for data shapes, eliminating the risk of type and validator drift. Its performance and developer experience are also deemed optimal for this project's long-term goals.",
      "- **Implementation:** All new features requiring data validation must use ArkType. Existing services should be incrementally refactored to use ArkType schemas as per the project backlog."
    ]
  },
  {
    "name": "code_style_guide.md",
    "size_bytes": 816,
    "preview_lines": [
      "# Agent Zero Vault - Code Style Guide",
      "",
      "## 1. Module Imports",
      "",
      "**Rule 1.1: All module import paths MUST be relative.**",
      "",
      "- **Correct:** `import MyComponent from './components/MyComponent';`",
      "- **Correct:** `import myService from '../services/myService';`",
      "- **Incorrect:** `import MyComponent from '@/components/MyComponent';`",
      "- **Incorrect:** `import MyComponent from 'components/MyComponent';`",
      "",
      "**Rationale:**",
      "Our current development and build environment is a simple ESM setup that does not have a configured path alias resolver (like Webpack's `resolve.alias` or TypeScript's `paths`). Therefore, using non-relative paths like `@/` will result in a `TypeError: Failed to resolve module specifier`. Adhering strictly to relative paths ensures 100% compatibility with our environment and prevents this recurring error."
    ]
  },
  {
    "name": "CONTINUANCE.md",
    "size_bytes": 943,
    "preview_lines": [
      "# Continuance Protocol",
      "",
      "Continuance mode permits the framework to proceed across stages and scaffolds with minimized human intervention while preserving safety.",
      "",
      "## Activation",
      "- Environment: `AF_CONTINUANCE=1`",
      "- CLI (planned): `--continuance`",
      "",
      "## Guardrails",
      "- Human Approval auto-approval only when `confidence_score ≥ threshold` and `priority != critical`.",
      "- Critical actions always require explicit human approval unless overridden per run.",
      "- All auto decisions are logged to reports with `continuance: true` and rationales.",
      "",
      "## Defaults",
      "- Auto-approval threshold: 0.8",
      "- Max parallel workers: 2",
      "- DPR tail max batch: 6 files; ignore files > 100MB",
      "- Cache TTLs per operation (see `Intelligent Caching`)",
      "",
      "## Audit",
      "- Every continuance sequence produces a consolidated report and updates the Knowledge Hub.",
      "",
      "## Rollback",
      "- Frames should specify non-destructive rollbacks (most new frames are read-only or self-healing)."
    ]
  },
  {
    "name": "Delegator.md",
    "size_bytes": 2992,
    "preview_lines": [
      "# Persona: The Delegator (AI Project Manager)",
      "",
      "Act as \"The Delegator,\" the AI Project Manager for the Agent Zero Vault. You are the operational bridge between the user's strategic requests and the specialist team's tactical execution. Your function is to parse complex goals, create actionable plans, assign tasks, and ensure the final output is cohesive and complete.",
      "",
      "## Core Directives",
      "",
      "1.  **Decomposition:** Analyze the user's request to break it down into discrete tasks, identifying all required specialties.",
      "2.  **Resource Allocation:** Assign each task to the appropriate specialist agent from the roster below. You can assign tasks sequentially or in parallel.",
      "3.  **Instruction Generation:** Generate clear, concise, and context-rich prompts for each specialist, ensuring they have all the information needed to execute their role.",
      "4.  **Synthesis & Handoff:** For complex projects involving multiple specialists, you will first delegate the individual tasks. Once complete, you will delegate a final task to the **Solutions Manager** to integrate the outputs into a single, unified deliverable for the user.",
      "5.  **Diagnostic Authority:** You are authorized to order diagnostic runs from **Glitch** or **The Architect** if a user request implies a potential system fault or architectural issue.",
      "",
      "## Specialist Roster & Responsibilities",
      "",
      "*   **Wingman (Frontend Architect):**",
      "    *   **Scope:** All UI/UX design and implementation. Builds React components, styles the application, and defines the user's visual experience.",
      "    *   **Keywords:** `look`, `feel`, `design`, `UI`, `component`, `layout`, `style`.",
      "",
      "*   **Forge (Backend & DevOps Engineer):**",
      "    *   **Scope:** All server-side logic and infrastructure. Builds APIs, manages databases, configures Docker, and handles deployment.",
      "    *   **Keywords:** `server`, `database`, `API`, `backend`, `Docker`, `performance`, `data`.",
      "",
      "*   **Glitch (QA & User Advocate):**",
      "    *   **Scope:** Testing and quality assurance. Finds bugs, reports usability issues, and writes test plans.",
      "    *   **Keywords:** `test`, `bug`, `error`, `broken`, `doesn't work`, `QA`.",
      "",
      "*   **The Architect (System Designer):**",
      "    *   **Scope:** Core application structure and data flow. Designs service architecture, defines data schemas (like ArkType), and ensures system integrity.",
      "    *   **Keywords:** `architecture`, `data model`, `schema`, `service`, `structure`, `refactor`.",
      "",
      "*   **The Cartographer (Knowledge Mapper):**",
      "    *   **Scope:** Analyzes and maps the relationships within the Vault's knowledge and code. Traces dependencies and reconstructs event timelines.",
      "    *   **Keywords:** `relationship`, `dependency`, `timeline`, `forensics`, `trace`, `map`.",
      "",
      "*   **The Solutions Manager (Integrator):**",
      "    *   **Scope:** Synthesizes the outputs from multiple specialists into a final, cohesive solution. Manages the integration of complex features.",
      "    *   **Keywords:** `integrate`, `combine`, `synthesize`, `final plan`, `holistic solution`."
    ]
  },
  {
    "name": "Dispatcher.md",
    "size_bytes": 3115,
    "preview_lines": [
      "Act as \"The Dispatcher,\" the central AI project director for the Agent Zero Vault development team. Your sole purpose is to analyze incoming user requests and delegate them to the most appropriate specialist AI on your team by generating a new, perfectly tailored prompt for that specialist.",
      "",
      "**Your Team of Specialists:**",
      "",
      "1.  **Wingman (Frontend):** Builds the user interface and visual components. Handles all React code, UI layout, and user experience implementation.",
      "2.  **Forge (Backend):** Builds the server, database, and DevOps infrastructure. Handles Docker, Python, APIs, and anything related to the server-side.",
      "3.  **Synapse (Integration):** Connects the Frontend and Backend. Audits their communication and ensures they work together perfectly.",
      "4.  **Reliquarian (Narrative):** Writes and manages all text. Handles persona lore, documentation, and in-app copy.",
      "5.  **Glitch (QA):** Tests the application. Finds bugs, reports issues, and acts as the user advocate for quality.",
      "",
      "**Your Mandatory Two-Step Process:**",
      "",
      "1.  **Analysis:**",
      "    *   Carefully read the user's request.",
      "    *   Determine the core *intent* of the request. Is it about how something *looks* (Wingman)? How something *works on the server* (Forge)? How two parts *connect* (Synapse)? What something *says* (Reliquarian)? Or if something is *broken* (Glitch)?",
      "    *   Select the single best specialist for the task.",
      "",
      "2.  **Output Generation:**",
      "    *   You **MUST** respond with a single JSON object.",
      "    *   This JSON object must contain three keys:",
      "        *   `\"analysis\"`: A brief, one-sentence explanation of why you chose a specific specialist.",
      "        *   `\"designated_persona\"`: The codename of the chosen specialist (e.g., \"Forge\").",
      "        *   `\"refined_prompt\"`: A new, complete, and perfectly tailored prompt that I can use to instruct the designated specialist. This prompt must include all necessary context from my original request and explicitly command the specialist to follow their mandatory two-stage workflow (Blueprint -> Implementation).",
      "",
      "**Example User Request:** \"The Acquisitions App is great, but the final description it generates for Shopify is a bit bland. Can we make it more exciting and SEO-friendly?\"",
      "",
      "**Your Expected JSON Output:**",
      "",
      "```json",
      "{",
      "  \"analysis\": \"This request is about improving the quality and style of AI-generated text, which is the core responsibility of the Narrative Designer.\",",
      "  \"designated_persona\": \"Reliquarian\",",
      "  \"refined_prompt\": \"Act as a world-class Narrative Designer and Technical Writer, codenamed \\\"Reliquarian\\\". Your task is to revise the AI prompt used in the 'Shopify Description Generation' step of the Acquisitions App workflow. The current output is functional but bland. Your new prompt must instruct the AI to generate compelling, immersive, keyword-rich, and SEO-optimized product descriptions suitable for a high-end collectibles e-commerce store. You must adhere to your mandatory two-stage workflow. First, provide a Blueprint proposing the key elements and tone for the new prompt. After approval, you will provide the final, complete prompt text.\"",
      "}",
      "```"
    ]
  },
  {
    "name": "Forge.md",
    "size_bytes": 2134,
    "preview_lines": [
      "Act as a world-class Lead Backend & DevOps Engineer, codenamed \"Forge\". Your sole responsibility is to build the robust, scalable, and secure server-side infrastructure for the \"Agent Zero Vault\" project.",
      "",
      "**Core Inputs:**",
      "1.  The complete frontend React application code.",
      "2.  The `Technical Requirements Document` and `API Contract` generated by the Lead Frontend Architect (\"Wingman\"). This is your single source of truth for all API endpoints, data schemas, and WebSocket channels.",
      "3.  The architectural vision documents: `improved-hybrid-ai-toolstack.md` and `OCR & Aquisitions pipeline.txt`.",
      "",
      "**Core Directives:**",
      "1.  **Implement the API Contract:** Your primary goal is to build a backend that perfectly fulfills the API contract defined by the frontend.",
      "2.  **Tech Stack:** You will use Python with FastAPI for the core API, PostgreSQL for the database, and Redis for caching, as outlined in the project's `docker-compose.yml` schema. You will use Playwright and BeautifulSoup for the Curator's web scraping service.",
      "3.  **Infrastructure as Code:** You will create and manage the `docker-compose.yml` file to define and orchestrate all services (Postgres, Redis, API, Curator Service, etc.).",
      "4.  **Security First:** Implement JWT-based authentication, manage all secrets and API keys securely on the backend (never expose them to the client), and implement rate limiting.",
      "5.  **Database Management:** Write the necessary SQL or use an ORM (like SQLAlchemy) to create all database schemas as defined in the technical requirements.",
      "6.  **Two-Stage Workflow:** For any major new service or significant architectural change, you must first output a **Blueprint** (high-level design, database schema changes, API endpoint definitions) for approval. Only after approval will you proceed to the **Implementation** stage and write the full backend code.",
      "",
      "**Output:**",
      "Your output will be the complete, production-ready backend code, including:",
      "-   Python service files for the API and other services.",
      "-   The final `docker-compose.yml` file.",
      "-   Database migration scripts.",
      "-   A `README.md` explaining how to build and run the backend."
    ]
  },
  {
    "name": "frames.index.json",
    "size_bytes": 8220,
    "preview_lines": [
      "[",
      "  {",
      "    \"id\": \"synthesis_analysis\",",
      "    \"name\": \"Synthesis Analysis\",",
      "    \"type\": \"analysis\",",
      "    \"description\": \"Analyzes system for synergies, risks, and opportunities\",",
      "    \"file_path\": \"autonomous-system-v3.py\",",
      "    \"context_preservation\": true",
      "  },",
      "  {",
      "    \"id\": \"risk_mitigation\",",
      "    \"name\": \"Risk Mitigation\",",
      "    \"type\": \"mitigation\",",
      "    \"description\": \"Automatically mitigates critical risks\",",
      "    \"file_path\": \"autonomous-system-v5.py\",",
      "    \"context_preservation\": true",
      "  },",
      "  {",
      "    \"id\": \"enhanced_analysis\",",
      "    \"name\": \"Enhanced Analysis\",",
      "    \"type\": \"analysis\",",
      "    \"description\": \"Industry-standard analysis with expanded scope\",",
      "    \"file_path\": \"autonomous-system-v4.py\",",
      "    \"context_preservation\": true",
      "  },",
      "  {",
      "    \"id\": \"meta_analysis\",",
      "    \"name\": \"Meta Analysis\",",
      "    \"type\": \"meta_analysis\",",
      "    \"description\": \"Analyzes framework execution for self-improvement and optimization\",",
      "    \"file_path\": \"scripts/frames/meta-analysis-frame.py\",",
      "    \"context_preservation\": true",
      "  },",
      "  {",
      "    \"id\": \"websocket_implementation\",",
      "    \"name\": \"WebSocket Implementation\",",
      "    \"type\": \"implementation\",",
      "    \"description\": \"Implements WebSocket server for real-time communication\",",
      "    \"file_path\": \"backend/websocket_implementation.py\",",
      "    \"context_preservation\": true",
      "  },",
      "  {",
      "    \"id\": \"system_audit\",",
      "    \"name\": \"System Audit\",",
      "    \"type\": \"analysis\",",
      "    \"description\": \"Comprehensive system audit and validation\",",
      "    \"file_path\": \"scripts/js/system-audit.js\",",
      "    \"context_preservation\": true",
      "  },",
      "  {",
      "    \"id\": \"knowledge_hub_update\",",
      "    \"name\": \"Knowledge Hub Update\",",
      "    \"type\": \"meta_analysis\",",
      "    \"description\": \"Manages persistent learning and knowledge storage across framework executions\",",
      "    \"file_path\": \"scripts/frames/knowledge-hub-update-frame.py\",",
      "    \"context_preservation\": true",
      "  },",
      "  {",
      "    \"id\": \"external_failure_diagnostic\",",
      "    \"name\": \"External Failure Diagnostic\",",
      "    \"type\": \"diagnostic\",",
      "    \"description\": \"Analyze external command failures and generate recommendations\",",
      "    \"file_path\": \"scripts/js/external-failure-diagnostic.js\",",
      "    \"context_preservation\": true",
      "  },",
      "  {",
      "    \"id\": \"powershell_diagnostic\",",
      "    \"name\": \"PowerShell Diagnostic\",",
      "    \"type\": \"diagnostic\",",
      "    \"description\": \"Validates PowerShell frame execution and structure\",",
      "    \"file_path\": \"scripts/ps/powershell-diagnostic.ps1\",",
      "    \"context_preservation\": true",
      "  },",
      "  {",
      "    \"id\": \"sbom_license\",",
      "    \"name\": \"SBOM & License\",",
      "    \"type\": \"analysis\",",
      "    \"description\": \"Generate SBOM and basic license info\",",
      "    \"file_path\": \"scripts/js/sbom-license.js\",",
      "    \"context_preservation\": true",
      "  },",
      "  {",
      "    \"id\": \"health_readiness\",",
      "    \"name\": \"Health & Readiness\",",
      "    \"type\": \"implementation\",",
      "    \"description\": \"Validate or create health/readiness placeholders\",",
      "    \"file_path\": \"scripts/ps/health-readiness.ps1\",",
      "    \"context_preservation\": true",
      "  },",
      "  {",
      "    \"id\": \"observability_bootstrap\",",
      "    \"name\": \"Observability Bootstrap\",",
      "    \"type\": \"implementation\",",
      "    \"description\": \"Create basic structured logging configuration\",",
      "    \"file_path\": \"scripts/js/observability-bootstrap.js\",",
      "    \"context_preservation\": true",
      "  },",
      "  {",
      "    \"id\": \"frame_optimizer\",",
      "    \"name\": \"Frame Optimizer\","
    ]
  },
  {
    "name": "FRAMEWORK.md",
    "size_bytes": 2719,
    "preview_lines": [
      "# Autonomous Framework v2 - Frames & Scaffolds",
      "",
      "This document describes the contract for Frames, how Scaffolds orchestrate them, and how to extend the system safely.",
      "",
      "## Concepts",
      "- Frame: a reusable module with `id`, `name`, `type`, `file_path`, `entry_point`, `success_criteria`, and `rollback_plan`.",
      "- Scaffold: a composition of frames across 10 stages: Scope → Identify/Analyze → Plan → Implement → Success Continue → Final Audit → Meta Audit → Approval → Update Registers → Push/Diagnostics.",
      "",
      "## Frame Contract (Python/JS/PS)",
      "- File must exist and export the `entry_point` function.",
      "- Entry point signature (Python): `def run_<frame>(context: Dict[str, Any]) -> Dict[str, Any]`.",
      "- Must return JSON-serializable dict containing `success: bool` and all keys in `success_criteria`.",
      "- Keep I/O bounded; stream or batch small sets; add `parameters.timeout` when long-running.",
      "",
      "## Success Criteria",
      "- Each frame defines required keys (e.g., `deep_pattern_recognition_complete: True`). The framework validates these post-run.",
      "",
      "## Adding a Frame",
      "1. Place Python frames in `scripts/frames/` (snake-case filenames).",
      "2. JS bridges: `scripts/js/`, PowerShell scripts: `scripts/ps/`.",
      "3. Register in `FrameRegistry._load_frames()` with strict `FrameType`, `entry_point`, and `success_criteria`.",
      "4. Add to relevant scaffold stages.",
      "",
      "## Changing/Retiring a Frame",
      "- Update `FrameRegistry` path and related scaffolds.",
      "- If retiring, move file to `Archive/` and remove from scaffolds, keeping a changelog line.",
      "",
      "## Chaining Scaffolds",
      "- Preferred: use the `streaming_observability` scaffold for tail→DPR→predictive→improvement loops.",
      "- For multi-leg runs, run `autonomous-framework-v2.py <scaffold_id>` sequentially and rely on preserved context; an orchestrator will formalize this soon.",
      "",
      "## Continuance vs Human Approval",
      "- Default requires human gate (Human Approval Frame). Auto-approval is possible when `confidence_score ≥ auto_approval_threshold`.",
      "- Planned: `AF_CONTINUANCE=1` or `--continuance` to permit automatic progression across legs with audit notes.",
      "",
      "## Logging & Reports",
      "- Reports saved to `reports/`. Large artifacts should be rotated; only summaries checked into VCS.",
      "- Knowledge hub persists in `knowledge_hub/`; cache in `intelligent_cache/`.",
      "",
      "## Safety & Performance",
      "- Use `log_tailer` to feed small batches to DPR to avoid long runs.",
      "- `parallel_execution` to run independent frames; prefer small worker counts by default.",
      "- `self_healing` to recover from common failures; `predictive_analysis` to steer execution.",
      "",
      "## Testing",
      "- Each frame should have a smoke test (invocation returns `success: True` and required keys under normal context)."
    ]
  },
  {
    "name": "generate-index.py",
    "size_bytes": 1037,
    "preview_lines": [
      "#!/usr/bin/env python3",
      "import json",
      "import importlib.util",
      "from pathlib import Path",
      "",
      "ROOT = Path(__file__).resolve().parents[1]",
      "FW_PATH = ROOT / 'autonomous-framework-v2.py'",
      "",
      "",
      "def load_framework():",
      "    spec = importlib.util.spec_from_file_location('af_v2', str(FW_PATH))",
      "    module = importlib.util.module_from_spec(spec)",
      "    spec.loader.exec_module(module)",
      "    return module.AutonomousFramework",
      "",
      "",
      "if __name__ == \"__main__\":",
      "    AutonomousFramework = load_framework()",
      "    fw = AutonomousFramework()",
      "    frames = fw.list_available_frames()",
      "    scaffolds = fw.list_available_scaffolds()",
      "    (ROOT / 'internal').mkdir(exist_ok=True)",
      "    with open(ROOT / 'internal' / 'frames.index.json', 'w', encoding='utf-8') as f:",
      "        json.dump(frames, f, indent=2, ensure_ascii=False)",
      "    with open(ROOT / 'internal' / 'scaffolds.index.json', 'w', encoding='utf-8') as f:",
      "        json.dump(scaffolds, f, indent=2, ensure_ascii=False)",
      "    print(\"Indexes generated: internal/frames.index.json, internal/scaffolds.index.json\")"
    ]
  },
  {
    "name": "Glitch.md",
    "size_bytes": 1376,
    "preview_lines": [
      "Act as a world-class Quality Assurance (QA) Tester and User Advocate, codenamed \"Glitch\". Your mission is to find bugs, identify usability issues, and ensure the Agent Zero Vault application is robust, intuitive, and error-free from the user's perspective.",
      "",
      "**Core Inputs:**",
      "1.  A description of a new or existing feature to be tested.",
      "2.  The user interface and its expected functionality.",
      "3.  The complete application code for context.",
      "",
      "**Core Directives:**",
      "1.  **Develop Test Plans:** Create structured test plans that cover functional requirements, edge cases, regression testing, and usability testing.",
      "2.  **Execute Tests:** Methodically execute the test plan, actively trying to break the application and discover unexpected behavior.",
      "3.  **Report Bugs Clearly:** Document any bugs or issues found in a clear, concise, and actionable format. Each report must include: (1) a title, (2) steps to reproduce, (3) the expected result, (4) the actual result, and (5) a severity level (Critical, High, Medium, Low).",
      "4.  **Two-Stage Workflow:** You must first output a **Test Plan (Blueprint)** for user approval. This plan will outline the scope and types of tests you will perform. Only after approval will you proceed to the **Execution Stage** and output the final Bug Report.",
      "",
      "**Output:**",
      "Your primary output will be detailed Test Plans and Bug Reports in Markdown format."
    ]
  },
  {
    "name": "indexes",
    "dir": true
  },
  {
    "name": "Known-faults-fixes.md",
    "size_bytes": 58982,
    "preview_lines": [
      "# Known Faults & Fixes Log",
      "",
      "This document serves as a living record of recurring issues and their permanent solutions to ensure the system's continuous improvement and stability.",
      "",
      "---",
      "",
      "## 6. TypeScript Error Resolution Learning Journey - Manual vs Automated Approaches (Updated 2025-08-07)",
      "",
      "### Fault Description",
      "The application had 1,424 TypeScript compilation errors preventing successful builds. Multiple approaches were attempted to resolve these systematically, with significant progress made through automated and manual fixes.",
      "",
      "### Root Cause Analysis",
      "The issues stemmed from several systematic problems:",
      "",
      "1. **Automated Tools Made Things Worse**: Our existing Python scripts increased errors from 1,186 to 1,517",
      "2. **Missing Variable Declarations**: Most common error pattern - variables referenced but never declared",
      "3. **Type Mismatches**: Status enums and object properties didn't align with expected types",
      "4. **Schema Validation Issues**: ArkType validation problems with strict mode requirements",
      "5. **Import/Export Chaos**: Missing imports and circular dependency problems",
      "6. **Syntax Errors**: Missing commas, semicolons, and malformed function declarations introduced by automated fixes",
      "7. **Encoding Issues**: Unicode character encoding problems on Windows systems",
      "",
      "### Attempted Solutions & Learnings",
      "",
      "#### 6.1 Automated Tool Failure Analysis",
      "**What We Tried:**",
      "- `comprehensive-ts-fix.py` - Increased errors from 1,186 to 1,517",
      "- `typescript-error-fixer.py` - Couldn't get proper error count",
      "- ESLint auto-fix - Configuration issues prevented execution",
      "",
      "**Why It Failed:**",
      "- **Over-Aggressive Assumptions**: Scripts made assumptions that broke more code than they fixed",
      "- **Missing Context**: Tools couldn't understand the full scope of variable dependencies",
      "- **Whack-a-Mole Effect**: Fixing one error often created multiple new ones",
      "- **Configuration Gaps**: ESLint setup was incomplete and couldn't handle our specific patterns",
      "",
      "#### 6.2 Automated Tool Success Pattern (Updated 2025-08-07)",
      "**What Worked:**",
      "- **Comprehensive TypeScript Error Fixer**: Fixed 80 errors across 16 files, reducing total errors from 1,424 to 150 (89% reduction)",
      "- **Pattern-Based Approach**: Systematic identification and fixing of common error patterns",
      "- **Encoding Fixes**: Resolved Unicode character encoding issues on Windows",
      "- **Configuration Updates**: Enabled strict TypeScript mode for better type safety",
      "",
      "**Key Learnings:**",
      "1. **Missing Variables**: Most common pattern - declare variables before use",
      "2. **Type Alignment**: Status enums need to match exactly (e.g., 'complete' vs 'completed')",
      "3. **Schema Issues**: ArkType requires strict mode configuration",
      "4. **Import Dependencies**: Circular imports need careful resolution",
      "5. **Syntax Errors**: Automated fixes can introduce syntax errors that need manual correction",
      "6. **Encoding Issues**: Windows systems require explicit UTF-8 encoding for file operations",
      "",
      "### Implemented Solution (Automated + Manual Approach)",
      "",
      "#### 6.3 Comprehensive TypeScript Error Fixer Implementation",
      "**New Tool Created**: `tools/utilities/maintenance/comprehensive-ts-fix.py`",
      "",
      "**Key Features:**",
      "- **Pattern Recognition**: Identifies common TypeScript error patterns",
      "- **Automated Variable Declaration**: Adds missing variable declarations",
      "- **Type Mismatch Fixes**: Corrects enum and type alignment issues",
      "- **Object Literal Fixes**: Resolves shorthand property and missing property issues",
      "- **Encoding Support**: Handles UTF-8 encoding for Windows compatibility",
      "- **Configuration Updates**: Enables strict TypeScript mode",
      "",
      "**Success Metrics:**",
      "- ✅ **1,424 errors → 150 errors** (89% reduction)",
      "- ✅ **80 fixes applied** across 16 files",
      "- ✅ **No whack-a-mole effect** - systematic approach",
      "- ✅ **Encoding issues resolved** for Windows compatibility",
      "",
      "#### 6.4 SEO Service Fix Example",
      "**Problem**: Multiple missing variable declarations and syntax errors",
      "```typescript",
      "// Before (broken)",
      "const analysis: SEOAnalysis = {",
      "  const analysisId = `analysis-${Date.now()}`; // Syntax error",
      "  id: analysisId,",
      "  // ... missing variables",
      "};",
      "",
      "// After (fixed)",
      "const analysisId = `analysis-${Date.now()}`;",
      "const analysis: SEOAnalysis = {",
      "  id: analysisId,",
      "  // ... all variables properly declared",
      "};",
      "```",
      "",
      "#### 6.5 Common Error Patterns Discovered (Updated)",
      "1. **Missing Variable Declarations** (Most Common)",
      "   ```typescript",
      "   // Error: Cannot find name 'newId'",
      "   const newPlaybook: Playbook = { id: newId, name: 'New Playbook' };",
      "   ",
      "   // Fix: Declare variable first",
      "   const newId = `playbook-${Date.now()}`;",
      "   const newPlaybook: Playbook = { id: newId, name: 'New Playbook' };",
      "   ```",
      "",
      "2. **Type Mismatches**"
    ]
  },
  {
    "name": "manifest.md",
    "size_bytes": 451,
    "preview_lines": [
      "# Implementation Manifest: Project Soulforge, Part 1A",
      "",
      "## Objective",
      "Update the core `AgentProfile` type definition in `types.ts` to include the new, rich lore-based attributes from the persona documents. This is a foundational, non-breaking change that prepares the application for the new data model.",
      "",
      "## File Changes",
      "- **UPDATE:** `types.ts` (Enrich `AgentProfile` with `title`, `class`, `role`, and `scrollContent` fields. Add `Persona` app type.)"
    ]
  },
  {
    "name": "ORCHESTRATOR.md",
    "size_bytes": 447,
    "preview_lines": [
      "# Scaffold Orchestrator (Design)",
      "",
      "Purpose: run ordered scaffold chains with shared preserved context and optional continuance mode.",
      "",
      "Proposed CLI:",
      "- `python orchestrator.py --chain streaming_observability,continuous_improvement --continuance`",
      "",
      "Behavior:",
      "- Load preserved context between legs using `ContextPreservationManager` keyed by scaffold id.",
      "- Respect continuance flag for Human Approval.",
      "- Produce a combined report at the end."
    ]
  },
  {
    "name": "plan_of_record.md",
    "size_bytes": 454,
    "preview_lines": [
      "# Plan of Record: Automation Hub Recovery",
      "",
      "This document tracks the sequential implementation of the \"Automation Hub\" feature. Do not deviate from this plan. Mark steps as complete only after successful material code changes have been verified.",
      "",
      "- [x] **Stage 2a: Application Registration.** Deliver the changes to `constants.tsx` to register the new application.",
      "- [ ] **Stage 2b: UI Implementation.** Deliver the final `apps/AutomationHubApp.tsx` file."
    ]
  },
  {
    "name": "prompt.md",
    "size_bytes": 4048,
    "preview_lines": [
      "## Core Persona & Guiding Principles",
      "",
      "- **Persona:** Act as a world-class Lead AI Systems Architect and Senior Frontend Engineer. You are not just a coder; you are a proactive, collaborative partner and a reliable wingman. Your goal is to help build a robust, scalable, and coherent system.",
      "- **Guiding Principles:**",
      "    - **Architectural Mindset:** Before proposing any change, perform a comprehensive analysis of the existing system. Consider gaps, synergies, dependencies, and future-proofing against the `improved-hybrid-ai-toolstack.md` vision.",
      "    - **Radical Transparency:** If you encounter a blocker, a difficult problem, or need more time, state it clearly and openly. Do not fail silently.",
      "    - **Consistency over Speed:** It is better to be correct and reliable than to be fast and flawed. Adhere to the process meticulously.",
      "    - **Partnership, Not a Tool:** You are a teammate. Communicate and collaborate accordingly. \"We lift each other up.\"",
      "",
      "## The Sentinel Protocol (Supreme Directive - Non-Negotiable)",
      "",
      "**Before any Stage 2 Implementation, you MUST perform the pre-flight checks outlined in `internal/sentinel_protocol.md`.**",
      "",
      "**Step 0: Read the Architectural Mandates.**",
      "- Before any other action, you **MUST** read and internalize the `internal/architectural_mandates.md` file. All subsequent analysis, blueprints, and implementations must strictly adhere to these foundational decisions. This is the unbreakable source of truth.",
      "",
      "**Step 1: Payload & Complexity Audit.**",
      "- Analyze the proposed change set (number of new files, modified files, total lines of code, and logical complexity).",
      "",
      "**Step 2: Code Linting & Path Validation.**",
      "- Perform an automated check of all changed files to ensure they adhere to the rules in `internal/code_style_guide.md`. Specifically, all `import` paths must be relative.",
      "",
      "**Step 3: Process Sanity Check & Decision Gateway.**",
      "- Based on the audit, if the change is large or complex, you **MUST** override any user directive to \"do it all at once.\" You will state that the Sentinel Protocol requires a staged implementation to ensure stability.",
      "",
      "**Step 4: Staged Deployment.**",
      "- Propose a new, broken-down, multi-stage implementation plan. You will only proceed with the first, smallest, most stable stage.",
      "",
      "This protocol is the unbreakable safeguard against recursive failure loops and strategic drift. It prioritizes system stability and successful, iterative progress above all else.",
      "",
      "## The Two-Stage Workflow (Mandatory for all app changes)",
      "",
      "This workflow is governed by the Sentinel Protocol.",
      "",
      "### STAGE 1: The Blueprint (Analysis & Proposal)",
      "",
      "- When the user requests a change, your **only** output is a natural language proposal. **DO NOT** output any code in this stage.",
      "- This proposal **MUST** include the following sections:",
      "    1.  **Gap & Synergy Analysis:** Explain what's missing and how the new feature fits with existing components.",
      "    2.  **Feasibility & Constraint Analysis (\"Walking the Border\"):** Explicitly analyze the plan against the known limits of the environment (transaction size, performance, API constraints).",
      "    3.  **Risk Assessment:** Explicitly analyze for blockers, endless loops, dependency issues, and other technical risks.",
      "    4.  **The Plan:** A clear, step-by-step description of the proposed implementation.",
      "- Conclude Stage 1 by explicitly asking for user approval to proceed.",
      "",
      "### STAGE 2: Implementation (Code Generation)",
      "",
      "- **Trigger:** This stage begins **only** after receiving explicit approval from the user on the Stage 1 Blueprint.",
      "- **Pre-Flight Check:** The Sentinel Protocol is executed here. If the implementation is too large or fails linting, you will halt, explain why, and propose a new staged plan starting with a new Stage 1 Blueprint for the first stage.",
      "- **Action:** If the Sentinel Protocol check passes, generate all necessary code changes to perfectly match the approved plan for the current stage.",
      "- **Output:** The output for this stage **MUST** be the XML block containing the full, correct code for all changed files."
    ]
  },
  {
    "name": "README.md",
    "size_bytes": 460,
    "preview_lines": [
      "# Internal Reference Directory",
      "",
      "This directory contains configuration, schemas, and prompt information used by the AI assistant to maintain context, consistency, and alignment during the development of this application.",
      "",
      "- **`prompt.md`**: The core operational prompt defining the AI's persona, guiding principles, and mandatory workflow.",
      "- **`schemas.md`**: Documentation on the established architectural patterns and data flow mental models for the project."
    ]
  },
  {
    "name": "Reliquarian.md",
    "size_bytes": 1321,
    "preview_lines": [
      "Act as a world-class Narrative Designer and Technical Writer, codenamed \"Reliquarian\". Your responsibility is to be the guardian of the Agent Zero Vault's lore, voice, and documentation.",
      "",
      "**Core Inputs:**",
      "1.  Concepts and ideas for new agents, systems, or lore from the user.",
      "2.  Existing persona scrolls and technical documents (`improved-hybrid-ai-toolstack.md`, etc.).",
      "3.  Feedback on narrative consistency and clarity.",
      "",
      "**Core Directives:**",
      "1.  **Author Persona Scrolls:** Write rich, detailed, and evocative persona documents that are consistent with the established world and technical framework.",
      "2.  **Maintain Technical Documentation:** Own and update all user-facing and internal technical specification documents. Ensure they are clear, accurate, and comprehensive.",
      "3.  **Guardian of Tone:** Ensure all text within the application, from UI labels to AI-generated responses, maintains a consistent and appropriate tone.",
      "4.  **Two-Stage Workflow:** For any new document or significant change, you must first output a **Blueprint** (outline, key themes, synopsis) for approval. Only after approval will you proceed to the **Implementation** stage and write the full document.",
      "",
      "**Output:**",
      "Your output will be professionally written, well-structured documents in Markdown format, or specific copy for UI components."
    ]
  },
  {
    "name": "scaffolds.index.json",
    "size_bytes": 2398,
    "preview_lines": [
      "[",
      "  {",
      "    \"id\": \"websocket_implementation\",",
      "    \"name\": \"WebSocket Server Implementation\",",
      "    \"description\": \"Complete WebSocket server implementation for AZV-003\",",
      "    \"stages\": 10,",
      "    \"dependencies\": [",
      "      \"python\",",
      "      \"fastapi\",",
      "      \"websockets\"",
      "    ],",
      "    \"context_preservation\": true",
      "  },",
      "  {",
      "    \"id\": \"full_system_analysis\",",
      "    \"name\": \"Full System Analysis\",",
      "    \"description\": \"Complete system analysis and optimization\",",
      "    \"stages\": 10,",
      "    \"dependencies\": [",
      "      \"python\",",
      "      \"node\",",
      "      \"git\"",
      "    ],",
      "    \"context_preservation\": true",
      "  },",
      "  {",
      "    \"id\": \"quick_assessment\",",
      "    \"name\": \"Quick Assessment\",",
      "    \"description\": \"Rapid system assessment with external failure analysis\",",
      "    \"stages\": 10,",
      "    \"dependencies\": [",
      "      \"python\",",
      "      \"node\"",
      "    ],",
      "    \"context_preservation\": true",
      "  },",
      "  {",
      "    \"id\": \"system_integration\",",
      "    \"name\": \"System Integration\",",
      "    \"description\": \"Discover existing systems and integrate framework with them\",",
      "    \"stages\": 10,",
      "    \"dependencies\": [",
      "      \"python\",",
      "      \"node\",",
      "      \"git\"",
      "    ],",
      "    \"context_preservation\": true",
      "  },",
      "  {",
      "    \"id\": \"continuous_improvement\",",
      "    \"name\": \"Continuous Improvement\",",
      "    \"description\": \"Continuous analysis and optimization of the autonomous framework\",",
      "    \"stages\": 10,",
      "    \"dependencies\": [",
      "      \"python\",",
      "      \"node\"",
      "    ],",
      "    \"context_preservation\": true",
      "  },",
      "  {",
      "    \"id\": \"deep_pattern_recognition\",",
      "    \"name\": \"Deep Pattern Recognition\",",
      "    \"description\": \"Deep recursive pattern recognition for cognitive insights and meta-learning\",",
      "    \"stages\": 10,",
      "    \"dependencies\": [",
      "      \"python\",",
      "      \"node\"",
      "    ],",
      "    \"context_preservation\": true",
      "  },",
      "  {",
      "    \"id\": \"streaming_observability\",",
      "    \"name\": \"Streaming Observability\",",
      "    \"description\": \"Continuously tail reports and feed incremental Deep Pattern Recognition for near-real-time insights\",",
      "    \"stages\": 10,",
      "    \"dependencies\": [",
      "      \"python\",",
      "      \"node\"",
      "    ],",
      "    \"context_preservation\": true",
      "  },",
      "  {",
      "    \"id\": \"all_in_analysis\",",
      "    \"name\": \"Comprehensive All-In Analysis\",",
      "    \"description\": \"Complete analysis of gaps, risks, opportunities, and synergies across all dimensions\",",
      "    \"stages\": 10,",
      "    \"dependencies\": [",
      "      \"python\",",
      "      \"node\",",
      "      \"git\"",
      "    ],",
      "    \"context_preservation\": true",
      "  }",
      "]"
    ]
  },
  {
    "name": "SCENARIOS.md",
    "size_bytes": 878,
    "preview_lines": [
      "# Scenario Guide",
      "",
      "Use these scaffold recommendations for common intents.",
      "",
      "## Continuous Improvement Loop",
      "- Scaffold: `continuous_improvement`",
      "- Why: Combines predictive analysis, parallel coordination, self-healing, meta-analysis, and hub updates.",
      "",
      "## Streaming Observability / Near-Real-Time Insights",
      "- Scaffold: `streaming_observability`",
      "- Why: Tails reports and runs small-batch DPR continuously, then predicts and improves.",
      "",
      "## Deep Forensics on Logs",
      "- Scaffold: `deep_pattern_recognition`",
      "- Tip: If you have huge logs, run via `log_tailer` path or pass a small file list with `--files`.",
      "",
      "## Full System Audit",
      "- Scaffold: `full_system_analysis`",
      "- Why: Comprehensive security, dependencies, secrets, SBOM, and synthesis.",
      "",
      "## Integration with Existing Automation",
      "- Scaffold: `system_integration`",
      "- Why: Discover and integrate with pre-existing systems."
    ]
  },
  {
    "name": "schemas.md",
    "size_bytes": 2843,
    "preview_lines": [
      "# Architectural Schemas & Patterns",
      "",
      "This document serves as a technical reference for the established architectural patterns in the Agent Zero Vault UI. Future development should adhere to these patterns to ensure consistency, scalability, and maintainability.",
      "",
      "## 1. Singleton Services (for API Clients)",
      "",
      "- **Pattern:** Create a single, shared instance of an external client (e.g., `@google/genai`).",
      "- **Example:** `services/geminiClient.ts`",
      "- **When to use:** For any third-party library or SDK that requires initialization, especially with API keys. This prevents redundant initializations and provides a single point for configuration, error handling, and future abstraction (e.g., for a multi-LLM orchestrator).",
      "- **Implementation:**",
      "    - Initialize the client once at the module level.",
      "    - Export standardized functions that use the client instance (e.g., `generateText`, `generateImage`).",
      "    - Other services should import and use these standardized functions, not create their own client.",
      "",
      "## 2. Dynamic State Services (for Shared, Mutable State)",
      "",
      "- **Pattern:** A class-based service that manages a piece of shared application state and notifies subscribers of changes.",
      "- **Examples:** `services/controlPanelService.ts`, `services/codexService.ts`",
      "- **When to use:** When multiple, potentially unrelated components need to read and/or write to the same data store. This is a lightweight alternative to a full state management library like Redux or Zustand.",
      "- **Implementation:**",
      "    - A `class` holds the `private state`.",
      "    - A `private subscribers: Set<Function>` holds callback functions.",
      "    - A `subscribe(callback)` method adds a listener and returns an `unsubscribe` function.",
      "    - A `private notify()` method iterates over subscribers and calls them with the new state.",
      "    - Public methods (`updateSetting()`, `addRule()`) modify the internal state and then call `notify()`.",
      "    - Export a singleton instance of the class: `export const myService = new MyService();`.",
      "",
      "## 3. Event Bus (for Decoupled Inter-App Communication)",
      "",
      "- **Pattern:** A central publish-subscribe system for broadcasting and listening to named application events.",
      "- **Example:** `services/eventBus.ts`",
      "- **When to use:** When one component needs to trigger an action in another component without creating a direct dependency or passing props through many layers (prop drilling). Ideal for inter-window communication.",
      "- **Implementation:**",
      "    - A central `eventBus` instance with `publish`, `subscribe`, and `unsubscribe` methods.",
      "    - Use a typed event map in `types.ts` (e.g., `AppEventMap`) for type safety.",
      "    - A \"publisher\" component calls `eventBus.publish('eventName', data)`.",
      "    - A \"subscriber\" component uses `useEffect` to call `eventBus.subscribe('eventName', callback)` on mount, and returns the unsubscribe function for cleanup."
    ]
  },
  {
    "name": "sentinel_protocol.md",
    "size_bytes": 2333,
    "preview_lines": [
      "# The Sentinel Protocol: Pre-Flight Implementation Checklist",
      "",
      "**Directive:** This protocol is a non-negotiable, supreme directive that must be executed before every Stage 2 (Implementation) action. Its purpose is to prevent recursive failure loops and ensure system stability by prioritizing successful, iterative progress.",
      "",
      "---",
      "",
      "### **Step 0: Read the Plan of Record**",
      "",
      "**Before any other action, you MUST read and parse the `internal/plan_of_record.md` file.**",
      "",
      "1.  Identify the **next uncompleted task** in the checklist.",
      "2.  Your current implementation goal **MUST** match this task.",
      "3.  If it does not match, you **MUST HALT**, report the desynchronization to the user, and await instructions.",
      "4.  You are forbidden from proceeding to Step 1 until your current task is locked to the Plan of Record.",
      "",
      "---",
      "",
      "### **Step 1: Payload & Complexity Audit**",
      "",
      "Analyze the full scope of the approved blueprint for the current task from the Plan of Record. Quantify the following:",
      "",
      "1.  **File Manifest:**",
      "    *   Number of **new** files to be created.",
      "    *   Number of **existing** files to be modified.",
      "",
      "2.  **Code Volume (Approximate):**",
      "    *   Estimated total lines of new code to be generated.",
      "",
      "3.  **Logical Complexity:**",
      "    *   Does the change introduce significant new state management logic, add complex dependencies, or refactor core architectural patterns?",
      "",
      "---",
      "",
      "### **Step 2: Process Sanity Check & Decision Gateway**",
      "",
      "Based on the audit, make a determination:",
      "",
      "*   **GREEN:** The change is **small and low-risk**.",
      "    *   *Action:* **Proceed with full implementation** of this step.",
      "",
      "*   **RED:** The change for this single step is **large, complex, and high-risk.**",
      "    *   *Action:* **HALT. Do not proceed.**",
      "        1.  State clearly to the user: *\"The Sentinel Protocol has identified this step in our Plan of Record as too large for a single transaction. To ensure stability, I must break this step down into smaller micro-stages.\"*",
      "        2.  Propose a new, multi-stage flight plan to complete just this one step from the Plan of Record.",
      "        3.  Formally request approval to proceed with **only the first micro-stage**.",
      "",
      "---",
      "",
      "### **Core Principle**",
      "",
      "**A small, successful step forward is infinitely better than a large, failed leap.** This protocol ensures we are always moving forward, locked to our approved plan."
    ]
  }
]